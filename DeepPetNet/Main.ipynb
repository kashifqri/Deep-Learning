{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a96872-e595-4484-ab46-72fed18ac7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c448d022-0d61-481d-8765-751dc09f295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59eb31cf-b58c-48d6-8c85-bbd9dc2ca792",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65c1b14d-4aaa-4b36-a730-603b5347ee19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cnn.add(Conv2D(32,(3,3),input_shape = (64,64,3),activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Conv2D(16,(3,3),activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84251aa7-63b5-4dcf-8d9d-d77a0fcd1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(64,activation='relu'))\n",
    "cnn.add(Dense(32,activation='relu'))\n",
    "cnn.add(Dense(16,activation='relu'))\n",
    "cnn.add(Dense(8,activation='relu'))\n",
    "cnn.add(Dense(4,activation='relu'))\n",
    "cnn.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e1396d-8039-4917-8c72-9433e79629ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7a7e5-f2f0-4efe-839e-57f3112a0ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9998 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1000s\u001b[0m 3s/step - loss: 0.6927 - val_loss: 0.7182\n",
      "Epoch 2/20\n",
      "\u001b[1m  1/312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - loss: 0.6932"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 1s/step - loss: 0.6932 - val_loss: 0.7191\n",
      "Epoch 3/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 2s/step - loss: 0.6711 - val_loss: 0.8963\n",
      "Epoch 4/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 151ms/step - loss: 0.7225 - val_loss: 0.8811\n",
      "Epoch 5/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 2s/step - loss: 0.6245 - val_loss: 1.0009\n",
      "Epoch 6/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 145ms/step - loss: 0.6778 - val_loss: 0.9994\n",
      "Epoch 7/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 2s/step - loss: 0.5982 - val_loss: 1.0692\n",
      "Epoch 8/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 114ms/step - loss: 0.4923 - val_loss: 1.0714\n",
      "Epoch 9/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 2s/step - loss: 0.5615 - val_loss: 1.0565\n",
      "Epoch 10/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 115ms/step - loss: 0.6709 - val_loss: 1.0526\n",
      "Epoch 11/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 1s/step - loss: 0.5468 - val_loss: 1.2264\n",
      "Epoch 12/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 129ms/step - loss: 0.4863 - val_loss: 1.2326\n",
      "Epoch 13/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 2s/step - loss: 0.5139 - val_loss: 1.2389\n",
      "Epoch 14/20\n",
      "\u001b[1m  1/312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 70ms/step - loss: 0.5131"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r\"C:\\Users\\basit\\Downloads\\CNN\\train_data\",\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        r\"C:\\Users\\basit\\Downloads\\CNN\\test_data\",\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "cnn.fit(train_generator,steps_per_epoch=312,epochs=20,validation_data=test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53626a9-654c-459c-8b2e-93006eb09022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d3e683-bd8e-4804-b2a1-c110601fa6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(r\"C:\\Users\\basit\\Downloads\\CNN\\cat\\CAT_02\\00000500_003.jpg\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464936fb-1646-4ddf-8ca1-62754d9680f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba27d06f-db42-4df0-b30c-fac26ebcac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.expand_dims(img,axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2d5813-9a05-4773-b730-9bae6ee39278",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = cnn.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6514cef-8700-408c-aa6b-0dc191448b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if p[0][0] < 0.5:\n",
    "    print(\"Dog\")\n",
    "else:\n",
    "    print(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81065ea6-ad2d-46a9-b6c6-13a6d51fdb89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e54ae4-8baf-484a-949f-c1cc38fdbf1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
